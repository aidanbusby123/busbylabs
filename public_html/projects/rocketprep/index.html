<!DOCTYPE html>
<html lang="">
    <head>
        <title>RocketPrepAI | AI Powered SAT Preparation</title>
        <meta name="author" content="Aidan Busby">
        <meta name="description" content="Behind the scenes of my AI powered SAT preparation service; our reason for building it, how we did it, and what we hope to accomplish">
        <link rel="stylesheet" href="../../style.css">
        <link rel="stylesheet" href="../../style.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/katex.min.css" integrity="sha384-Pu5+C18nP5dwykLJOhd2U4Xen7rjScHN/qusop27hdd2drI+lL5KvX7YntvT8yew" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/katex.min.js" integrity="sha384-2B8pfmZZ6JlVoScJm/5hQfNS2TI/6hPqDZInzzPc8oHpN5SgeNOf4LzREO6p5YtZ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <main>
            <h1>RocketPrepAI: AI Powered Test Prep</h1>
            <br>
            <p>Over the past couple of months, I have been developing an AI powered SAT preparation
                service called <a href="https://rocketprep.ai">RocketPrepAI</a>. It has been an exciting journey for me and the rest of my team,
                given this is our first shot at the startup scene. Our goal is to provide low-cost, high quality
                SAT practice and assitance for students who don't have the resources to pay for private tutors.
                Today, I thought I'd go over how RocketPrepAI works and what makes us unique.
            </p>
            
            <h3>Our Team</h3>
            <div class="team-container">
                <img class="team-photo" src="media/team_photo.jpg" alt="RocketPrepAI Team Photo">
                
                <div class="team-captions">
                    <div class="team-member">
                        <h4>Leo McClintock</h4>
                        <p>Head of marketing</p>
                    </div>
                    
                    <div class="team-member">
                        <h4>Nathan Vuong</h4>
                        <p>Head of Finance</p>
                    </div>
                    
                    <div class="team-member">
                        <h4>Arthur Johnston</h4>
                        <p>Swiss Army Knife</p>
                    </div>
                    
                    <div class="team-member">
                        <h4>Aidan Busby</h4>
                        <p>Founder, lead engineer</p>
                    </div>
                </div>
            </div>
           
            <br>
            <br>
            <br>
            <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vS0JHvcF4HlpiXoVIJjpq76MKWs89ZUSEsMq4ZjRejaxXXR8kmqKO_lK05Dw7RfEviYlAO56eltshWL/pubembed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
            <h2>How does RocketPrepAI work?</h2>

            <p>
            
            RocketPrepAI uses LLMs (Large Language Models) to generate quality mock SAT practice questions, and offers these to users
            through adaptive and manual study features. Our adaptive study sessions utilize a statistical framework called <b>Item Response Theory</b>,
            which uses bayesian probability to give users questions based off of how helpful that question is likely to be for their study journeys.
            <br>
            <br>
            As of December 2025, we are looking into ways to further improve our adaptive study features and offer an automated way for users to generate
            day-by-day dynamic study plans that optimize the learning process by accounting for the "forgetting curve", the arch nemesis of SAT preparation.
            Our Item Response Theory framework already provides a solution to this for short-term practice, but for practice over long periods of time a more 
            high-level solution would be nice, and certainly revolutionary!
            <br>

             

            </p>
            <h3>Question Generation</h3>
            <p>
                Generating SAT questions and other semantically dense forms of text is a difficult job for current Large Language Models. Despite their apparent understanding
                of semantics, LLMs have a tendency to mimic an understanding of semantics while being confined to an understanding of lexicology. This is easily apparent when 
                attempting to generate a mock SAT question without any fine tuning or prompting techniques: The LLM generates a sequence of words that <i>appears</i> to be semantically
                complex upon initial review due to word choice and the cliche tone of Large Language Models, offering a guise of sophistication and complexity that falls apart upon actually
                reading the generated passage, and realizing the extremely shallow nature of the question.<br><br>
                In other words, the LLM generates a passage or question that contains a number of fancy words and appears similar to other SAT questions on a token-by-token scale,
                yet the text lacks any nuance or complexity and is a dumbfoundingly superficial.<br>
                <br>
                <br>
                Here is an example of a question generated using ChatGPT with minimal prompting techniques:
                <br>
                <br>
                <br>
                <img src="media/firstq.png">
                <br>
                <br>
                <br>
                While here is an example of a question relying on proper prompting techniques:
                <br>
                <br>
                <br>
                <img src="media/secondq.png">
                <br>

                
                Specifically, we use LLM-as-a-judge to generate feedback for question drafts. We provide some feedback from other, example questions as well, to ensure the feedback agent
                has an approximate idea of how to generate the feedback in an appropriate manner.

                <br>
                <br>

                Generate rough draft -> Analyze rough draft and come up with AI generated feedback -> Apply AI generated feedback -> Format question -> Human review
                <br>
                <br>

            </p>
            <h3>Adaptive Practice</h3>
            <p>One of the hurdles of effective SAT preparation is determining how to properly divy up one's time across different topics. One way to approach this issue is by
                implementing Item Response Theory (IRT).
                <br>
                <br>
                IRT works by tracking a user's responses and using the relative difficulty of the questions' difficulty combined with whether the user got the question correct or not
                to converge on an estimate of the user's ability.
                <br>
                <br>
                Given the user's ability, we can optimize their learning process by selecting questions based on how much information that question is likely to impart to the user; by information,
                we are referring to whether or not the question will help the user <i>grow</i>. A terribly easy question isn't likely to do much to help, while neither is a terribly hard question.

                <br>
                <br>
                IRT model:
                <br>

                $$P(\theta) = \frac{\exp(\theta - b)}{1 + \exp(\theta - b)}$$

                <br>
                \(P(\theta)\) is the probability that the user gets a question of difficulty b correct, given a user ability of \(\theta\)

                <br>
                <br>
                In order to actually calculate the user's ability level, we use a specific technique called Expected A Posteriori (EAP). EAP works by using the previous estimated probability distrobution for 
                a user's ability combined with their response and some bayesian magic to figure out their new expected ability level distrobution after a response.
                <br>
                <br>
                The math looks like this: 
                <br>
                <img src="media/eap.gif">
                <br>
                Where \(B\) is the random variable describing the user's prior ability distribution, and we are finding the posterior distribution.
            </p>
            
        </main>
    </body>
</html>
